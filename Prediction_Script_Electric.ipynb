{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from keras.models import load_model\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from keras.models import Sequential,load_model\n",
    "\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vehicle_Type = 'Electric_Vehicles'\n",
    "Folder = 'Dataset/SampleData'\n",
    "\n",
    "df = pd.read_csv(f'{Folder}/{Vehicle_Type}_Final_Training_Samples.csv')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processsing Inputs and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.values.tolist()\n",
    "DataSet = np.array(df,dtype=float)\n",
    "\n",
    "print('*******************************')\n",
    "\n",
    "Tupple = np.shape(DataSet)                  #34011 Segments x 18 Features\n",
    "Number_of_Records = Tupple[0]\n",
    "Number_of_Features = Tupple[1]\n",
    "\n",
    "print(f'Number_of_Records = {Number_of_Records}')\n",
    "print(f'Number_of_Features = {Number_of_Features}')\n",
    "\n",
    "\n",
    "#Processing Sample_Inputs without Target Feature\n",
    "\n",
    "X = np.zeros((Number_of_Records, Number_of_Features - 1))\n",
    "for t in range(Number_of_Records):\n",
    "    X[t] = DataSet[t, :(Number_of_Features-1)]\n",
    "\n",
    "print(f'Input_Size = {np.shape(X)}')\n",
    "\n",
    "#Processings Sample_Lables with Target feature ('Fuel_Consumed')\n",
    "\n",
    "y = np.zeros((Number_of_Records,))\n",
    "for t in range(Number_of_Records):\n",
    "    y[t] = DataSet[t][Number_of_Features-1]\n",
    "\n",
    "print(f'Label_Size = {np.shape(y)}')\n",
    "\n",
    "\n",
    "print('*******************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "print(f'Training_Input = {np.shape(X_train)}')\n",
    "print(f'Training_Labels = {np.shape(y_train)}')\n",
    "\n",
    "print(f'Testing_inputs = {np.shape(X_test)}')\n",
    "print(f'Testing_Labels = {np.shape(y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Time_Needed Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Time Needed for predicting for samples with longer intervals\n",
    "Time_needed = []\n",
    "\n",
    "for i in X_test:\n",
    "    Time_needed.append(i[1])\n",
    "\n",
    "print(np.shape(Time_needed))\n",
    "\n",
    "#Deleting Time_Needed before Training\n",
    "\n",
    "X_train = np.delete(X_train, 1, 1)\n",
    "X_test = np.delete(X_test, 1, 1)\n",
    "\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))\n",
    "\n",
    "T = np.shape(X_test) #For Plotting\n",
    "\n",
    "print(T)\n",
    "\n",
    "Length_of_TestData = T[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Model - Feed Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimpleFeedForward_Model(number_of_epoch):\n",
    "    \n",
    "    # print(f'number_of_iteration = {number_of_epoch}')\n",
    "    # FF_model = Sequential()\n",
    "    #\n",
    "    # FF_model.add(Dense(100,  input_shape=(Number_of_Features-2,), activation=\"sigmoid\"))\n",
    "    # FF_model.add(Dense(80, activation=\"sigmoid\"))\n",
    "    # FF_model.add(Dense(1, activation = \"linear\"))\n",
    "    #\n",
    "    # optimizer = keras.optimizers.SGD(lr=0.1)\n",
    "    # def mean_error(y_test, y_pred):\n",
    "    #     return tf.reduce_mean(y_pred - y_test)\n",
    "    #\n",
    "    # checkpoint = ModelCheckpoint(f'{Folder}/PredictionModels/Electric/FF_model-All-{epoch:03d}-{loss:03f}-{val_loss:03f}.h5', verbose=1, monitor='val_loss',\n",
    "    #                              save_best_only=True, mode='auto')\n",
    "    #\n",
    "    # FF_model.compile(loss='mse', optimizer = 'adam', metrics=['mae'])\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    # history = FF_model.fit(X_train, y_train,\n",
    "    #     shuffle=True,\n",
    "    #     epochs=number_of_epoch,\n",
    "    #     batch_size=128,\n",
    "    #                        # validation_split=0.05,\n",
    "    #     # validation_data=(X_val,y_val),\n",
    "    #     validation_data=(X_test, y_test),\n",
    "    #     callbacks=[checkpoint],\n",
    "    #     verbose=2)\n",
    "    #\n",
    "    # # print(FF_model.summary())\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    # print(history.history.keys())\n",
    "    #\n",
    "\n",
    "    #\n",
    "    # #summarize history for loss\n",
    "    # plt.plot(history.history['loss'])\n",
    "    # plt.plot(history.history['val_loss'])\n",
    "    # plt.title('Model Loss')\n",
    "    # plt.ylabel('Loss = MSE')\n",
    "    # plt.xlabel('Iteration')\n",
    "    # plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    #\n",
    "    # plt.show()\n",
    "\n",
    "    # #load model\n",
    "    FF_model = load_model(f'{Folder}/PredictionModels/Electric/FF_model-ALL-799-0.031906-0.031194.h5')\n",
    "\n",
    "    print(\"MSE\\t\\tMAE\")\n",
    "\n",
    "    scores = FF_model.evaluate(X_train, y_train, verbose=2)\n",
    "    print(\"Training Set Loss: {}\".format(scores))\n",
    "\n",
    "    # scores = FF_model.evaluate(X_val, y_val, verbose=2)\n",
    "    # print(\"Validation Set Loss: {}\".format(scores))\n",
    "\n",
    "    scores = FF_model.evaluate(X_test, y_test, verbose=2)\n",
    "    print(\"Testing Set Loss: {}\".format(scores))\n",
    "\n",
    "    y_pred = FF_model.predict(X_test, verbose=2, batch_size=64)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecisionTree_Model():\n",
    "    # DT_regressor = DecisionTreeRegressor(max_depth= Number_of_Features,\n",
    "    #                                   splitter = 'best',\n",
    "    #                                   criterion=\"mse\", min_samples_leaf=0.001)\n",
    "\n",
    "    # DT_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # y_pred = DT_regressor.predict(X_train)\n",
    "\n",
    "    # MSE = np.sum(((y_train - y_pred) ** 2) / len(y_train))\n",
    "    # print(f'MSE on Train = {MSE}')\n",
    "\n",
    "    # y_pred = DT_regressor.predict(X_test)\n",
    "\n",
    "    # MSE = np.sum(((y_test - y_pred) ** 2) / len(y_test))\n",
    "    # print(f'MSE on Test = {MSE}')\n",
    "\n",
    "    # RMSE = np.sqrt(np.sum(((y_test - y_pred) ** 2) / len(y_test)))\n",
    "    # print(f'RMSE = {RMSE}')\n",
    "\n",
    "    # MAE = np.sum(abs(y_test - y_pred) / len(y_test))\n",
    "    # print(f'MAE = {MAE}')\n",
    "\n",
    "    filename = f'{Folder}/PredictionModels/Electric/finalized_DT_model.sav'\n",
    "    #pickle.dump(DT_regressor, open(filename, 'wb'))\n",
    "\n",
    "    ###load the model from disk\n",
    "    loaded_model = pickle.load(open(filename, 'rb'))\n",
    "    y_pred = loaded_model.predict(X_test)\n",
    "    score = loaded_model.score(X_test, y_test)\n",
    "    print(f'R^2 Score = {score}')\n",
    "\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearRegression_Model():\n",
    "\n",
    "    # regression_model = LinearRegression(fit_intercept=True, normalize=True)\n",
    "    # regression_model.fit(X_train, y_train)\n",
    "\n",
    "    # # regression coefficients\n",
    "\n",
    "    # print('Coefficients for each feature:')\n",
    "    # print(regression_model.coef_)\n",
    "\n",
    "    # R_Square = regression_model.score(X_test, y_test)  # Explained variance score: 1 is perfect prediction\n",
    "    # print(f'R_Square = {R_Square}')\n",
    "\n",
    "    # y_pred = regression_model.predict(X_train)\n",
    "\n",
    "    # regression_model_mse = mean_squared_error(y_train, y_pred)\n",
    "    # regression_model_mae = mean_absolute_error(y_train, y_pred)\n",
    "\n",
    "    # print(f'regression_model_mse on Train = {regression_model_mse}')\n",
    "    # print(f'regression_model_mae on Train = {regression_model_mae}')\n",
    "\n",
    "    # y_pred = regression_model.predict(X_test)\n",
    "\n",
    "    # regression_model_mse = mean_squared_error(y_test,y_pred)\n",
    "    # regression_model_mae = mean_absolute_error(y_test,y_pred)\n",
    "\n",
    "    # print(f'regression_model_mse on Test = {regression_model_mse}')\n",
    "    # print(f'regression_model_mae on test = {regression_model_mae}')\n",
    "\n",
    "\n",
    "\n",
    "    filename = f'{Folder}/PredictionModels/Electric/finalized_LR_model.sav'\n",
    "    #pickle.dump(regression_model, open(filename, 'wb'))\n",
    "    \n",
    "    \n",
    "    ###load the model from disk\n",
    "    loaded_model = pickle.load(open(filename, 'rb'))\n",
    "    y_pred = loaded_model.predict(X_test)\n",
    "    score = loaded_model.score(X_test, y_test)\n",
    "    print(f'R^2 Score = {score}')\n",
    "\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Predicted vs Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plotting_Pred_Actual(Model_Name,Actual_Values,PredictedValues,Length_of_TestData,Count):\n",
    "\n",
    "    #Each iteration will plot results for 25 samples.\n",
    "    \n",
    "    initial = 0\n",
    "    final = 25\n",
    "    for initial in range(0,Length_of_TestData+1,25):\n",
    "        Samples = list(range(initial,final,1))\n",
    "    \n",
    "        plt.grid(color='b', linestyle='--', linewidth=0.1)\n",
    "        plt.plot(PredictedValues[initial:final],'*',color = 'k')\n",
    "        plt.plot(Actual_Values[initial:final], '--',marker = 'o',color = 'r')\n",
    "        plt.xlabel(f'Samples from {initial} to {final-1}',size = 20)#,weight='bold')\n",
    "        xi = [i for i in range(0,len(Samples),1)]\n",
    "        plt.xticks(xi,Samples,rotation=90)\n",
    "    \n",
    "        plt.ylabel('Energy Consumption',size=20)#,weight='bold')\n",
    "        plt.title(f'Predicted Energy Consumption vs Actual Energy Consumption\\n{Model_Name}',size=20)#,weight='bold')\n",
    "        plt.legend(('Predicted Value', 'Actual Value'),\n",
    "                   loc='upper right',fontsize = 'x-large')\n",
    "    \n",
    "    \n",
    "        plt.show()\n",
    "\n",
    "        final = final + 25\n",
    "        \n",
    "        if final > Length_of_TestData:\n",
    "            final = Length_of_TestData\n",
    "        \n",
    "        if final>Count:  #will plot for the first 50 Samples\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Results in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_Results_to_Files(Model_Name,Actual_Values,PredictedValues,Time_needed):\n",
    "\n",
    "    Abs_Loss = []\n",
    "    for i in range(0,len(Actual_Values)):\n",
    "        Abs_Loss.append(abs(PredictedValues[i] - Actual_Values[i]))\n",
    "\n",
    "    Abs_Loss = np.array(Abs_Loss)\n",
    "    PredictedValues = np.array(PredictedValues)\n",
    "    Actual_Values=np.array(Actual_Values)\n",
    "    Loss_in_Percentage = []\n",
    "\n",
    "\n",
    "\n",
    "    Predicted_Fuel_Consumption = pd.DataFrame({\"Predicted_Values\": PredictedValues,\n",
    "                                                \"Actual_Values\":Actual_Values,\n",
    "                                               \"Abs_Loss\":Abs_Loss,\n",
    "                                                \"Time_needed\":Time_needed})\n",
    "\n",
    "    CSV_Name_Loss = f'{Model_Name}_Predicted_Fuel_Consumption_for_{Vehicle_Type}.csv'\n",
    "    Predicted_Fuel_Consumption.to_csv(f'{Folder}/Results/Electric/{CSV_Name_Loss}',index=False)\n",
    "    print('\\n\\n***********CSV Saved************\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with Different Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Models = ['DecisionTree','SimpleFeedForward','LinearRegression']\n",
    "\n",
    "Actual_Values = y_test\n",
    "\n",
    "for Model_Name in Models:\n",
    "\n",
    "    if Model_Name == 'LinearRegression':\n",
    "        print('\\n\\n\\n*************Executing LR*************\\n\\n')\n",
    "        PredictedValues = LinearRegression_Model()\n",
    "\n",
    "    if Model_Name == 'DecisionTree':\n",
    "        print('\\n\\n\\n*************Executing DT*************\\n\\n')\n",
    "        PredictedValues = DecisionTree_Model()\n",
    "\n",
    "    if Model_Name == 'SimpleFeedForward':\n",
    "        print('\\n\\n\\n*************Executing FF*************\\n\\n')\n",
    "        number_of_iteration = 800\n",
    "        PredictedValues_FF = SimpleFeedForward_Model(number_of_iteration)\n",
    "        Model_Name = 'SimpleFeedForward'\n",
    "        PredictedValues = []\n",
    "        for i in PredictedValues_FF:\n",
    "            for j in i:\n",
    "                PredictedValues.append(j)\n",
    "        print(len(PredictedValues))\n",
    "\n",
    "    ## Plot outputs\n",
    "    Count = 50             #Indicates Plotting for how many samples\n",
    "    Plotting_Pred_Actual(Model_Name,Actual_Values,PredictedValues,Length_of_TestData,Count)\n",
    "\n",
    "\n",
    "    ## Creating a CSV with the predicted values\n",
    "\n",
    "    Save_Results_to_Files(Model_Name,Actual_Values,PredictedValues,Time_needed)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
